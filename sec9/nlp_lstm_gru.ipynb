{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字数 110323\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "with open(\"kaijin_nijumenso.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text_original = f.read()\n",
    "\n",
    "text = re.sub(\"《[^》]+》\", \"\", text_original)\n",
    "text = re.sub(\"［[^］]+］\", \"\", text)\n",
    "text = re.sub(\"[｜ 　]\", \"\", text)\n",
    "print(\"文字数\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "n_mid = 256  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/72f90tzd1cg5sbjg1h1kpnpc0000gp/T/ipykernel_11347/2293283784.py:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
      "/var/folders/1z/72f90tzd1cg5sbjg1h1kpnpc0000gp/T/ipykernel_11347/2293283784.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xの形状 (110313, 10, 1249)\n",
      "tの形状 (110313, 1249)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = {}\n",
    "for i, char in enumerate(chars):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}\n",
    "for i, char in enumerate(chars):\n",
    "    indices_char[i] = char\n",
    "\n",
    "time_chars = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - n_rnn):\n",
    "    time_chars.append(text[i:i+n_rnn])\n",
    "    next_chars.append(text[i+n_rnn])\n",
    "\n",
    "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
    "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n",
    "for i, t_cs in enumerate(time_chars):\n",
    "    t[i, char_indices[next_chars[i]]] = 1\n",
    "    for j, char in enumerate(t_cs):\n",
    "        x[i, j, char_indices[char]] = 1\n",
    "\n",
    "print(\"xの形状\", x.shape)\n",
    "print(\"tの形状\", t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 256)               1542144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1249)              320993    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,863,137\n",
      "Trainable params: 1,863,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:47:34.921225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-08-06 20:47:34.922207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-08-06 20:47:34.923021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))\n",
    "model_lstm.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    " \n",
    "def on_epoch_end(epoch, logs):\n",
    "    print(\"エポック: \", epoch)\n",
    "\n",
    "    beta = 5  # 確率分布を調整する定数\n",
    "    prev_text = text[0:n_rnn]  # 入力に使う文字\n",
    "    created_text = prev_text  # 生成されるテキスト\n",
    "    \n",
    "    print(\"シード: \", created_text)\n",
    "\n",
    "    for i in range(400):\n",
    "        # 入力をone-hot表現に\n",
    "        x_pred = np.zeros((1, n_rnn, len(chars)))\n",
    "        for j, char in enumerate(prev_text):\n",
    "            x_pred[0, j, char_indices[char]] = 1\n",
    "        \n",
    "        # 予測を行い、次の文字を得る\n",
    "        y = model.predict(x_pred)\n",
    "        p_power = y[0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        created_text += next_char\n",
    "        prev_text = prev_text[1:] + next_char\n",
    "\n",
    "    print(created_text)\n",
    "    print()\n",
    "\n",
    "# エポック終了後に実行される関数を設定\n",
    "epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lstm\n",
    "history_lstm = model_lstm.fit(x, t,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[epock_end_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(n_mid, input_shape=(n_rnn, len(chars))))\n",
    "model_gru.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_gru.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gru\n",
    "history_gru = model_gru.fit(x, t,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[epock_end_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_lstm = history_lstm.history['loss']\n",
    "loss_gru = history_gru.history['loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
    "plt.plot(np.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_10_14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
